{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронная сеть  \n",
    "Предсказываение сжимания / разжимания пальцев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 64)                12864     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 15,523\n",
      "Trainable params: 15,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "# model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(200,)))\n",
    "model.add(layers.Dense(64))\n",
    "# model.add(layers.LSTM(128))\n",
    "# model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "# model.add(layers.SimpleRNN(32))\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.Dense(16))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "model.add(layers.Dense(3))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tf.keras.Input(shape=(100,))  # Returns an input placeholder\n",
    "\n",
    "# # A layer instance is callable on a tensor, and returns a tensor.\n",
    "# x = layers.Dense(64, activation='relu')(inputs)\n",
    "# x = layers.Dense(64, activation='relu')(x)\n",
    "# x = layers.LSTM(64)(x)\n",
    "# predictions = layers.Dense(2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs\n",
    "# model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 64)                12864     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 15,523\n",
      "Trainable params: 15,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def smooth(x,window_len=11,window='hanning'):\n",
    "    if x.ndim != 1:\n",
    "        raise (ValueError, \"smooth only accepts 1 dimension arrays.\")\n",
    "\n",
    "    if x.size < window_len:\n",
    "        raise(ValueError, \"Input vector needs to be bigger than window size.\")\n",
    "\n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise (ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "\n",
    "\n",
    "    s=numpy.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=numpy.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('numpy.'+window+'(window_len)')\n",
    "\n",
    "    y=numpy.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../datasets/binary_regression/ds_1000/dataset.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_0</th>\n",
       "      <th>e_1</th>\n",
       "      <th>e_2</th>\n",
       "      <th>e_3</th>\n",
       "      <th>e_4</th>\n",
       "      <th>e_5</th>\n",
       "      <th>e_6</th>\n",
       "      <th>e_7</th>\n",
       "      <th>e_8</th>\n",
       "      <th>e_9</th>\n",
       "      <th>...</th>\n",
       "      <th>e_191</th>\n",
       "      <th>e_192</th>\n",
       "      <th>e_193</th>\n",
       "      <th>e_194</th>\n",
       "      <th>e_195</th>\n",
       "      <th>e_196</th>\n",
       "      <th>e_197</th>\n",
       "      <th>e_198</th>\n",
       "      <th>e_199</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>514.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>215.476654</td>\n",
       "      <td>215.346304</td>\n",
       "      <td>215.394942</td>\n",
       "      <td>215.649805</td>\n",
       "      <td>215.836576</td>\n",
       "      <td>215.727626</td>\n",
       "      <td>215.566148</td>\n",
       "      <td>215.503891</td>\n",
       "      <td>215.517510</td>\n",
       "      <td>215.538911</td>\n",
       "      <td>...</td>\n",
       "      <td>117.182879</td>\n",
       "      <td>117.202335</td>\n",
       "      <td>117.064202</td>\n",
       "      <td>117.161479</td>\n",
       "      <td>116.284047</td>\n",
       "      <td>116.340467</td>\n",
       "      <td>115.426070</td>\n",
       "      <td>115.260700</td>\n",
       "      <td>115.447471</td>\n",
       "      <td>-0.044747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>214.891596</td>\n",
       "      <td>214.766850</td>\n",
       "      <td>214.808255</td>\n",
       "      <td>215.062441</td>\n",
       "      <td>215.253395</td>\n",
       "      <td>215.143634</td>\n",
       "      <td>214.982769</td>\n",
       "      <td>214.922355</td>\n",
       "      <td>214.932068</td>\n",
       "      <td>214.953958</td>\n",
       "      <td>...</td>\n",
       "      <td>191.747605</td>\n",
       "      <td>191.775082</td>\n",
       "      <td>191.549112</td>\n",
       "      <td>191.715695</td>\n",
       "      <td>191.215495</td>\n",
       "      <td>191.301205</td>\n",
       "      <td>190.737829</td>\n",
       "      <td>190.469324</td>\n",
       "      <td>190.780019</td>\n",
       "      <td>0.806855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>420.500000</td>\n",
       "      <td>420.500000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.750000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>421.750000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              e_0         e_1         e_2         e_3         e_4         e_5  \\\n",
       "count  514.000000  514.000000  514.000000  514.000000  514.000000  514.000000   \n",
       "mean   215.476654  215.346304  215.394942  215.649805  215.836576  215.727626   \n",
       "std    214.891596  214.766850  214.808255  215.062441  215.253395  215.143634   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%    420.000000  420.000000  421.000000  420.500000  420.500000  421.000000   \n",
       "75%    428.000000  428.000000  429.000000  429.750000  430.000000  429.000000   \n",
       "max    448.000000  448.000000  446.000000  448.000000  448.000000  448.000000   \n",
       "\n",
       "              e_6         e_7         e_8         e_9  ...       e_191  \\\n",
       "count  514.000000  514.000000  514.000000  514.000000  ...  514.000000   \n",
       "mean   215.566148  215.503891  215.517510  215.538911  ...  117.182879   \n",
       "std    214.982769  214.922355  214.932068  214.953958  ...  191.747605   \n",
       "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "50%    421.000000  421.000000  420.000000  420.000000  ...    0.000000   \n",
       "75%    429.000000  429.000000  428.000000  429.000000  ...  422.000000   \n",
       "max    448.000000  448.000000  448.000000  446.000000  ...  447.000000   \n",
       "\n",
       "            e_192       e_193       e_194       e_195       e_196       e_197  \\\n",
       "count  514.000000  514.000000  514.000000  514.000000  514.000000  514.000000   \n",
       "mean   117.202335  117.064202  117.161479  116.284047  116.340467  115.426070   \n",
       "std    191.775082  191.549112  191.715695  191.215495  191.301205  190.737829   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%    422.000000  422.000000  422.000000  421.750000  422.000000  422.000000   \n",
       "max    448.000000  447.000000  447.000000  447.000000  448.000000  448.000000   \n",
       "\n",
       "            e_198       e_199       label  \n",
       "count  514.000000  514.000000  514.000000  \n",
       "mean   115.260700  115.447471   -0.044747  \n",
       "std    190.469324  190.780019    0.806855  \n",
       "min      0.000000    0.000000   -1.000000  \n",
       "25%      0.000000    0.000000   -1.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%    421.000000  422.000000    1.000000  \n",
       "max    448.000000  446.000000    1.000000  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset[dataset.label != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values = dataset.loc[:, \"e_0\":\"e_199\"].to_numpy()\n",
    "lables_my = []\n",
    "for l in dataset.label[:]:\n",
    "    if l == 1:\n",
    "        lables_my.append([1, 0, 0])\n",
    "    elif l == 0 :\n",
    "        lables_my.append([0, 1, 0])\n",
    "    elif l == -1 :\n",
    "        lables_my.append([0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables_my = np.array(lables_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lables_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values_post = []\n",
    "for each in X_values:\n",
    "    X_values_post.append(np.log([i+1 for i in each]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.random.random((1000, 100))\n",
    "# labels_1 = np.random.random((26, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_values, lables_my, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "344/344 [==============================] - 0s 1ms/step - loss: nan - acc: 0.3052\n",
      "Epoch 2/20\n",
      "344/344 [==============================] - 0s 82us/step - loss: nan - acc: 0.2907\n",
      "Epoch 3/20\n",
      "344/344 [==============================] - 0s 150us/step - loss: nan - acc: 0.2907\n",
      "Epoch 4/20\n",
      "344/344 [==============================] - 0s 78us/step - loss: nan - acc: 0.2907\n",
      "Epoch 5/20\n",
      "344/344 [==============================] - 0s 87us/step - loss: nan - acc: 0.2907\n",
      "Epoch 6/20\n",
      "344/344 [==============================] - 0s 102us/step - loss: nan - acc: 0.2907\n",
      "Epoch 7/20\n",
      "344/344 [==============================] - 0s 62us/step - loss: nan - acc: 0.2907\n",
      "Epoch 8/20\n",
      "344/344 [==============================] - 0s 79us/step - loss: nan - acc: 0.2907\n",
      "Epoch 9/20\n",
      "344/344 [==============================] - 0s 76us/step - loss: nan - acc: 0.2907\n",
      "Epoch 10/20\n",
      "344/344 [==============================] - 0s 87us/step - loss: nan - acc: 0.2907\n",
      "Epoch 11/20\n",
      "344/344 [==============================] - 0s 104us/step - loss: nan - acc: 0.2907\n",
      "Epoch 12/20\n",
      "344/344 [==============================] - 0s 83us/step - loss: nan - acc: 0.2907\n",
      "Epoch 13/20\n",
      "344/344 [==============================] - 0s 91us/step - loss: nan - acc: 0.2907\n",
      "Epoch 14/20\n",
      "344/344 [==============================] - 0s 121us/step - loss: nan - acc: 0.2907\n",
      "Epoch 15/20\n",
      "344/344 [==============================] - 0s 98us/step - loss: nan - acc: 0.2907\n",
      "Epoch 16/20\n",
      "344/344 [==============================] - 0s 100us/step - loss: nan - acc: 0.2907\n",
      "Epoch 17/20\n",
      "344/344 [==============================] - 0s 99us/step - loss: nan - acc: 0.2907\n",
      "Epoch 18/20\n",
      "344/344 [==============================] - 0s 135us/step - loss: nan - acc: 0.2907\n",
      "Epoch 19/20\n",
      "344/344 [==============================] - 0s 130us/step - loss: nan - acc: 0.2907\n",
      "Epoch 20/20\n",
      "344/344 [==============================] - 0s 110us/step - loss: nan - acc: 0.2907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12738eb70>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for r in res:\n",
    "    print(round(r[0]), round(r[1])) #, round(r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
